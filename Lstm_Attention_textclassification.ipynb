{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lstm_Attention_textclassification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/NehruNidamanuru/Deep-learning/blob/master/Lstm_Attention_textclassification.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "1B_cshhqJhfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5930
        },
        "outputId": "1338f61b-6e2a-4052-cf28-4fc5019d8591"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/\")\n",
        "!ls"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2014-Nehru-Java-68.docx\r\n",
            "2018-07-26-13-47-54-515_1532593074515_XXXPN5331X_Acknowledgement.zip\r\n",
            "alg 2017_12_07_07_06_54.mp3\r\n",
            "alg2017_12_08_07_13_43.mp3\r\n",
            "alg2017_12_11_07_16_22.mp3\r\n",
            "alg2017_12_12_07_16_00.mp3\r\n",
            "alg2017_12_13_07_11_54.mp3\r\n",
            "Amar_Mainframes.docx\r\n",
            "anomoly.pkl\r\n",
            "AP5+PreTunnel-MOTION-1526577006112-2018-137-17-10-02.68.mp4\r\n",
            "bottlenck_model_cropped_vgg16_2class.h5\r\n",
            "bottlenck_model_vgg_3_class_svm.h5\r\n",
            "bottlenck_model_vgg_3_class_svm_small.h5\r\n",
            "Capturerrb.jpg\r\n",
            "Colab Notebooks\r\n",
            "Data (6adc3e0f).rar\r\n",
            "Data.rar\r\n",
            "Deeplearning\r\n",
            "drive\r\n",
            "DSC_0053 (3e8ecf81).JPG\r\n",
            "DSC_0053.JPG\r\n",
            "DSC_0054 (603618a3).JPG\r\n",
            "DSC_0054.JPG\r\n",
            "DSC_0055 (3fddaa93).JPG\r\n",
            "DSC_0055.JPG\r\n",
            "DSC_0056 (f80bbf40).JPG\r\n",
            "DSC_0056.JPG\r\n",
            "DSC_0057 (091332e3).JPG\r\n",
            "DSC_0057.JPG\r\n",
            "DSC_0058 (07c667ca).JPG\r\n",
            "DSC_0058.JPG\r\n",
            "DSC_0059 (600f059c).JPG\r\n",
            "DSC_0059.JPG\r\n",
            "DSC_0060 (c60e80b8).JPG\r\n",
            "DSC_0060.JPG\r\n",
            "DSC_0061 (9ee580f7).JPG\r\n",
            "DSC_0061.JPG\r\n",
            "DSC_0062 (10f61870).JPG\r\n",
            "DSC_0062.JPG\r\n",
            "DSC_0063 (310db53e).JPG\r\n",
            "DSC_0063.JPG\r\n",
            "DSC_0064 (611156ec).JPG\r\n",
            "DSC_0064.JPG\r\n",
            "DSC_0065 (00521816).JPG\r\n",
            "DSC_0065.JPG\r\n",
            "DSC_0066 (8b930fd7).JPG\r\n",
            "DSC_0066.JPG\r\n",
            "DSC_0067 (3ae78328).JPG\r\n",
            "DSC_0067.JPG\r\n",
            "DSC_0068 (5fa50bc9).JPG\r\n",
            "DSC_0068.JPG\r\n",
            "DSC_0069 (5b0cefaf).JPG\r\n",
            "DSC_0069.JPG\r\n",
            "DSC_0070 (deaee454).JPG\r\n",
            "DSC_0070.JPG\r\n",
            "DSC_0071 (250c6d81).JPG\r\n",
            "DSC_0071.JPG\r\n",
            "DSC_0072 (0f0a571d).JPG\r\n",
            "DSC_0072.JPG\r\n",
            "DSC_0073 (311210bd).JPG\r\n",
            "DSC_0073.JPG\r\n",
            "DSC_0074 (637f70a9).JPG\r\n",
            "DSC_0074.JPG\r\n",
            "DSC_0075 (c2e4b6bb).JPG\r\n",
            "DSC_0075.JPG\r\n",
            "DSC_0076 (62132c74).JPG\r\n",
            "DSC_0076.JPG\r\n",
            "DSC_0077 (261ef554).JPG\r\n",
            "DSC_0077.JPG\r\n",
            "DSC_0078 (815e4bef).JPG\r\n",
            "DSC_0078.JPG\r\n",
            "DSC_0079 (5453eb34).JPG\r\n",
            "DSC_0079.JPG\r\n",
            "DSC_0080 (bf9f4a27).JPG\r\n",
            "DSC_0080.JPG\r\n",
            "DSC_0081 (69fd2f1c).JPG\r\n",
            "DSC_0081.JPG\r\n",
            "DSC_0082 (71c693d5).JPG\r\n",
            "DSC_0082.JPG\r\n",
            "DSC_0083 (2ee06f07).JPG\r\n",
            "DSC_0083.JPG\r\n",
            "DSC_0084 (359dfa1d).JPG\r\n",
            "DSC_0084.JPG\r\n",
            "DSC_0085 (87b845dc).JPG\r\n",
            "DSC_0085.JPG\r\n",
            "DSC_0086 (edd9ce05).JPG\r\n",
            "DSC_0086.JPG\r\n",
            "DSC_0087 (c11e5044).JPG\r\n",
            "DSC_0087.JPG\r\n",
            "DSC_0088 (2a2a3723).JPG\r\n",
            "DSC_0088.JPG\r\n",
            "DSC_0089 (4e0b28df).JPG\r\n",
            "DSC_0089.JPG\r\n",
            "DSC_0093 (2d82d88d).JPG\r\n",
            "DSC_0093.JPG\r\n",
            "DSC_0094 (e7d72716).JPG\r\n",
            "DSC_0094.JPG\r\n",
            "DSC_0095 (625e47f2).JPG\r\n",
            "DSC_0095.JPG\r\n",
            "DSC_0096 (f66ee2c9).JPG\r\n",
            "DSC_0096.JPG\r\n",
            "DSC_0097 (90cc5e74).JPG\r\n",
            "DSC_0097.JPG\r\n",
            "DSC_0098 (5c88d48d).JPG\r\n",
            "DSC_0098.JPG\r\n",
            "DSC_0099 (d0f27dd1).JPG\r\n",
            "DSC_0099.JPG\r\n",
            "DSC_0100 (98d89f03).JPG\r\n",
            "DSC_0100.JPG\r\n",
            "DSC_0101 (17b3d232).JPG\r\n",
            "DSC_0101.JPG\r\n",
            "DSC_0102 (036cf9c9).JPG\r\n",
            "DSC_0102.JPG\r\n",
            "DSC_0103 (09d94a12).JPG\r\n",
            "DSC_0103.JPG\r\n",
            "DSC_0104 (96db46be).JPG\r\n",
            "DSC_0104.JPG\r\n",
            "DSC_0105 (e682c9c4).JPG\r\n",
            "DSC_0105.JPG\r\n",
            "DSC_0106 (cb4b0f40).JPG\r\n",
            "DSC_0106.JPG\r\n",
            "DSC_0107 (25b92a9d).JPG\r\n",
            "DSC_0107.JPG\r\n",
            "DSC_0108 (b65f0376).JPG\r\n",
            "DSC_0108.JPG\r\n",
            "DSC_0109 (9652273f).JPG\r\n",
            "DSC_0109.JPG\r\n",
            "DSC_0110 (e54f17de).JPG\r\n",
            "DSC_0110.JPG\r\n",
            "DSC_0111 (706aa760).JPG\r\n",
            "DSC_0111.JPG\r\n",
            "DSC_0112 (d826d545).JPG\r\n",
            "DSC_0112.JPG\r\n",
            "DSC_0113 (ea2d6be8).JPG\r\n",
            "DSC_0113.JPG\r\n",
            "DSC_0114 (4db8fba3).JPG\r\n",
            "DSC_0114.JPG\r\n",
            "DSC_0115 (f3664de9).JPG\r\n",
            "DSC_0115.JPG\r\n",
            "DSC_0116 (2fdc8c33).JPG\r\n",
            "DSC_0116.JPG\r\n",
            "DSC_0117 (e609c221).JPG\r\n",
            "DSC_0117.JPG\r\n",
            "DSC_0118 (e14b2b4f).JPG\r\n",
            "DSC_0118.JPG\r\n",
            "DSC_0119 (df0dfe59).JPG\r\n",
            "DSC_0119.JPG\r\n",
            "DSC_0120 (5f224c90).JPG\r\n",
            "DSC_0120.JPG\r\n",
            "DSC_0121 (91696725).JPG\r\n",
            "DSC_0121.JPG\r\n",
            "DSC_0122 (29f39550).JPG\r\n",
            "DSC_0122.JPG\r\n",
            "DSC_0123 (83631e1f).JPG\r\n",
            "DSC_0123.JPG\r\n",
            "DSC_0124 (81599fef).JPG\r\n",
            "DSC_0124.JPG\r\n",
            "DSC_0125 (608e869b).JPG\r\n",
            "DSC_0125.JPG\r\n",
            "DSC_0126 (90b30285).JPG\r\n",
            "DSC_0126.JPG\r\n",
            "DSC_0127 (d16d1655).JPG\r\n",
            "DSC_0127.JPG\r\n",
            "DSC_0129 (a59c9aee).JPG\r\n",
            "DSC_0129.JPG\r\n",
            "DSC_0130 (59f3ef36).JPG\r\n",
            "DSC_0130.JPG\r\n",
            "DSC_0131 (1ea8503b).JPG\r\n",
            "DSC_0131.JPG\r\n",
            "embedding_weight_matrix_custom_neh.txt\r\n",
            "Gmail - Fwd: Indix ML Challenge.pdf\r\n",
            "How to get started with Drive\r\n",
            "IMG_20150113_082747.jpg\r\n",
            "IMG_20150115_151437.jpg\r\n",
            "IMG_20150304_210856_edit.jpg\r\n",
            "IMG_20150304_210856.jpg\r\n",
            "IMG_20150318_065617_hdr.jpg\r\n",
            "IMG_20150318_065721.jpg\r\n",
            "IMG_20150318_165515.jpg\r\n",
            "IMG_20150322_171008.jpg\r\n",
            "IMG_20150322_171012.jpg\r\n",
            "IMG_20150322_171020.jpg\r\n",
            "IMG_20150322_171028.jpg\r\n",
            "IMG_20150328_110605.jpg\r\n",
            "IMG_20150328_110608.jpg\r\n",
            "IMG_20150328_110640.jpg\r\n",
            "IMG_20150418_202627.jpg\r\n",
            "IMG_20150418_202630.jpg\r\n",
            "IMG_20150418_202720.jpg\r\n",
            "IMG_20150418_204415.jpg\r\n",
            "IMG_20150418_204431.jpg\r\n",
            "IMG_20150418_204438.jpg\r\n",
            "IMG_20150418_205209.jpg\r\n",
            "IMG_20150418_205213.jpg\r\n",
            "IMG_20150418_210907.jpg\r\n",
            "IMG_20150418_210913.jpg\r\n",
            "IMG_20150418_210921.jpg\r\n",
            "IMG_20150418_211011.jpg\r\n",
            "IMG_20150418_211130.jpg\r\n",
            "IMG_20150419_081909.jpg\r\n",
            "IMG_20150419_082235.jpg\r\n",
            "IMG_20150421_073918.jpg\r\n",
            "IMG_20150421_073936.jpg\r\n",
            "IMG_20150421_074005.jpg\r\n",
            "IMG_20150421_074018.jpg\r\n",
            "IMG_20150423_080504.jpg\r\n",
            "IMG_20150424_085018.jpg\r\n",
            "IMG_20150424_085021.jpg\r\n",
            "IMG_20150424_095119.jpg\r\n",
            "IMG_20150424_095144.jpg\r\n",
            "IMG_20150424_095159.jpg\r\n",
            "IMG_20150424_103516.jpg\r\n",
            "IMG_20150424_103558.jpg\r\n",
            "IMG_20150424_103609.jpg\r\n",
            "IMG_20150424_103640.jpg\r\n",
            "IMG_20150424_111920.jpg\r\n",
            "IMG_20150424_123105.jpg\r\n",
            "IMG_20150424_123114.jpg\r\n",
            "IMG_20150424_123126 (6531956d).jpg\r\n",
            "IMG_20150424_123126.jpg\r\n",
            "IMG_20150424_123143 (ba6422d5).jpg\r\n",
            "IMG_20150424_123143.jpg\r\n",
            "IMG_20150424_123146 (a9094cb6).jpg\r\n",
            "IMG_20150424_123146.jpg\r\n",
            "IMG_20150424_123226 (4fa5d2a8).jpg\r\n",
            "IMG_20150424_123226.jpg\r\n",
            "IMG_20150424_123229.jpg\r\n",
            "IMG_20150424_124736.jpg\r\n",
            "IMG_20150424_124802.jpg\r\n",
            "IMG_20150424_124830.jpg\r\n",
            "IMG_20150425_090405.jpg\r\n",
            "IMG_20150425_090412.jpg\r\n",
            "IMG_20150425_090427.jpg\r\n",
            "IMG_20150425_090430.jpg\r\n",
            "IMG_20150425_092621.jpg\r\n",
            "IMG_20150425_093022.jpg\r\n",
            "IMG_20150425_093359.jpg\r\n",
            "IMG_20150425_093404.jpg\r\n",
            "IMG_20150425_093809.jpg\r\n",
            "IMG_20150425_094857.jpg\r\n",
            "IMG_20150425_094903.jpg\r\n",
            "IMG_20150425_111104.jpg\r\n",
            "IMG_20150425_111113.jpg\r\n",
            "IMG_20150425_111136.jpg\r\n",
            "IMG_20150425_111141.jpg\r\n",
            "IMG_20150425_111212.jpg\r\n",
            "IMG_20150425_111500.jpg\r\n",
            "IMG_20150425_111658.jpg\r\n",
            "IMG_20150425_111707.jpg\r\n",
            "IMG_20150425_111726.jpg\r\n",
            "IMG_20150425_111732.jpg\r\n",
            "IMG_20150425_111817.jpg\r\n",
            "IMG_20150425_112135.jpg\r\n",
            "IMG_20150425_112819_hdr.jpg\r\n",
            "IMG_20150425_112933_hdr.jpg\r\n",
            "IMG_20150425_112940_hdr.jpg\r\n",
            "IMG_20150425_112947_hdr.jpg\r\n",
            "IMG_20150425_112952_hdr.jpg\r\n",
            "IMG_20150425_113311.jpg\r\n",
            "IMG_20150425_113842.jpg\r\n",
            "IMG_20150425_114134.jpg\r\n",
            "IMG_20150425_114138.jpg\r\n",
            "IMG_20150425_114435.jpg\r\n",
            "IMG_20150425_115035.jpg\r\n",
            "IMG_20150425_115040.jpg\r\n",
            "IMG_20150425_120915.jpg\r\n",
            "IMG_20150425_120925.jpg\r\n",
            "IMG_20150425_121723.jpg\r\n",
            "IMG_20150425_121730.jpg\r\n",
            "IMG_20150425_121946.jpg\r\n",
            "IMG_20150425_122025.jpg\r\n",
            "IMG_20150425_122030.jpg\r\n",
            "IMG_20150425_122101.jpg\r\n",
            "IMG_20150425_122109.jpg\r\n",
            "IMG_20150425_122124.jpg\r\n",
            "IMG_20150425_122126.jpg\r\n",
            "IMG_20150425_122223.jpg\r\n",
            "IMG_20150425_122235.jpg\r\n",
            "IMG_20150425_122237.jpg\r\n",
            "IMG_20150425_122305.jpg\r\n",
            "IMG_20150425_122307.jpg\r\n",
            "IMG_20150425_122320.jpg\r\n",
            "IMG_20150425_122323.jpg\r\n",
            "IMG_20150425_122900.jpg\r\n",
            "IMG_20150425_122902.jpg\r\n",
            "IMG_20150425_123047.jpg\r\n",
            "IMG_20150425_123050.jpg\r\n",
            "IMG_20150425_123056.jpg\r\n",
            "IMG_20150425_123747_hdr.jpg\r\n",
            "IMG_20150425_124154_hdr.jpg\r\n",
            "IMG_20150425_124257_hdr.jpg\r\n",
            "IMG_20150425_124309_hdr.jpg\r\n",
            "IMG_20150425_124318_hdr.jpg\r\n",
            "IMG_20150425_124400_hdr.jpg\r\n",
            "IMG_20150425_124406_hdr.jpg\r\n",
            "IMG_20150425_124708_hdr.jpg\r\n",
            "IMG_20150425_125131_hdr.jpg\r\n",
            "IMG_20150425_125136_hdr.jpg\r\n",
            "IMG_20150425_125204_hdr.jpg\r\n",
            "IMG_20150425_125953_hdr.jpg\r\n",
            "IMG_20150425_130001_hdr.jpg\r\n",
            "IMG_20150425_130200_hdr.jpg\r\n",
            "IMG_20150425_130236_hdr.jpg\r\n",
            "IMG_20150425_130244_hdr.jpg\r\n",
            "IMG_20150425_130323_hdr.jpg\r\n",
            "IMG_20150425_130654_hdr.jpg\r\n",
            "IMG_20150425_130733_hdr.jpg\r\n",
            "IMG_20150425_130746_hdr.jpg\r\n",
            "IMG_20150425_130913_hdr.jpg\r\n",
            "IMG_20150425_130927_hdr.jpg\r\n",
            "incidents_wo_502196531.csv\r\n",
            "ML-20180516T150812Z-001.zip\r\n",
            "model11705_2clas.h5\r\n",
            "model11705.h5\r\n",
            "model23105_2class.h5\r\n",
            "model_incident_classification_lstm_attention.json\r\n",
            "model_incidents_attention_lstm_word_vec_100d_new.h5\r\n",
            "my_lstm_model.h5\r\n",
            "Nehru2expmf35084 (06995839).docx\r\n",
            "Nehru2expmf35084 (d1fa2fbf).docx\r\n",
            "Nehru2expmf35084.docx\r\n",
            "Nehru_DsG_Dp.docx\r\n",
            "Nehru_DsG_Dp.docx.odt\r\n",
            "nehrumf16exp (1).docx\r\n",
            "nehrumf16exp (a030966d).docx\r\n",
            "nehrumf16exp.docx\r\n",
            "Nehrumf2exp (18349109).docx\r\n",
            "Nehrumf2exp (1e346683).docx\r\n",
            "Nehrumf2exp (c519e6a8).docx\r\n",
            "Nehrumf2exp (c86f6935).docx\r\n",
            "Nehrumf2exp.docx\r\n",
            "Nehrumf2exp (ebb50213).docx\r\n",
            "Nehrumf2exp (efe4af84).docx\r\n",
            "Nehrumf2exp (faec2b23).docx\r\n",
            "Nehrumf2exp.pdf\r\n",
            "Nehrumf.doc\r\n",
            "Nehrumf (e0bdce27).doc\r\n",
            "Nehru personal\r\n",
            "Nehru.rar\r\n",
            "Ramesh\r\n",
            "Recordings Algorithms\r\n",
            "State Bank of India.pdf\r\n",
            "Submission.csv\r\n",
            "Submission.csv.ods\r\n",
            "train.csv\r\n",
            "Untitled\r\n",
            "Untitled0.ipynb\r\n",
            "Untitled1.ipynb\r\n",
            "Untitled2.ipynb\r\n",
            "Untitled3.ipynb\r\n",
            "Untitled4.ipynb\r\n",
            "util1.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0KCdL3F8KgE6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.layers import concatenate\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import nltk\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize          \n",
        "from nltk.corpus import stopwords\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Input, Bidirectional,TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XEKDFQ3hJwVj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data_file = pd.read_csv(\"incidents_wo_502196531.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfq3dRKMJzHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "df8c8088-80bc-478a-d1b5-fd4288233e42"
      },
      "cell_type": "code",
      "source": [
        "data_file.info()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 25263 entries, 0 to 25262\n",
            "Data columns (total 16 columns):\n",
            "number               25263 non-null object\n",
            "priority             25263 non-null object\n",
            "assigned_to          25239 non-null object\n",
            "assignment_group     25147 non-null object\n",
            "sys_created_on       25263 non-null object\n",
            "state                25263 non-null object\n",
            "cmdb_ci              25017 non-null object\n",
            "incident_state       25263 non-null object\n",
            "category             25263 non-null object\n",
            "subcategory          551 non-null object\n",
            "short_description    25242 non-null object\n",
            "description          16137 non-null object\n",
            "contact_type         25263 non-null object\n",
            "close_code           25262 non-null object\n",
            "close_notes          25262 non-null object\n",
            "sys_created_by       25263 non-null object\n",
            "dtypes: object(16)\n",
            "memory usage: 3.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NF-lpEU6KHE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "294e494d-0a97-4e7f-86a8-2f9ba268fb51"
      },
      "cell_type": "code",
      "source": [
        "data_file=data_file.dropna(subset=['cmdb_ci','short_description'])\n",
        "data_file.shape\n",
        "data_file.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 25017 entries, 0 to 25262\n",
            "Data columns (total 16 columns):\n",
            "number               25017 non-null object\n",
            "priority             25017 non-null object\n",
            "assigned_to          25017 non-null object\n",
            "assignment_group     25017 non-null object\n",
            "sys_created_on       25017 non-null object\n",
            "state                25017 non-null object\n",
            "cmdb_ci              25017 non-null object\n",
            "incident_state       25017 non-null object\n",
            "category             25017 non-null object\n",
            "subcategory          551 non-null object\n",
            "short_description    25017 non-null object\n",
            "description          16137 non-null object\n",
            "contact_type         25017 non-null object\n",
            "close_code           25016 non-null object\n",
            "close_notes          25016 non-null object\n",
            "sys_created_by       25017 non-null object\n",
            "dtypes: object(16)\n",
            "memory usage: 3.2+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "srbKG2bjKM38",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "8c1b94fa-8602-4e1a-b85d-c8d872671379"
      },
      "cell_type": "code",
      "source": [
        "vc = data_file['cmdb_ci'].value_counts()\n",
        "u  = [i not in set(vc[vc<=100].index) for i in data_file['cmdb_ci']]\n",
        "data_file = data_file[u]\n",
        "data_file.info()\n",
        "list1 = list(data_file['cmdb_ci'].unique())\n",
        "len(list1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 20227 entries, 0 to 25258\n",
            "Data columns (total 16 columns):\n",
            "number               20227 non-null object\n",
            "priority             20227 non-null object\n",
            "assigned_to          20227 non-null object\n",
            "assignment_group     20227 non-null object\n",
            "sys_created_on       20227 non-null object\n",
            "state                20227 non-null object\n",
            "cmdb_ci              20227 non-null object\n",
            "incident_state       20227 non-null object\n",
            "category             20227 non-null object\n",
            "subcategory          379 non-null object\n",
            "short_description    20227 non-null object\n",
            "description          12642 non-null object\n",
            "contact_type         20227 non-null object\n",
            "close_code           20227 non-null object\n",
            "close_notes          20227 non-null object\n",
            "sys_created_by       20227 non-null object\n",
            "dtypes: object(16)\n",
            "memory usage: 2.6+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "rfuXdrMCKrCr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def buildVocabulary(sentence):\n",
        "    text = list(set(sentence))\n",
        "    tokenizer = Tokenizer(lower=False, split=' ')\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "doqJoh5RKzNr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cleanSentence(sentence):\n",
        "     sentence_clean= re.sub(\"[^a-zA-Z0-9]\",\" \", str(sentence))\n",
        "     sentence_clean = sentence_clean.lower()\n",
        "     tokens = word_tokenize(sentence_clean)\n",
        "     stop_words = set(stopwords.words(\"english\"))\n",
        "     sentence_clean_words = [w for w in tokens if not w in stop_words]\n",
        "     return ' '.join(sentence_clean_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NLdpF8uWK1f7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "cd986e45-c04c-427e-e973-1610c5aa31e5"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#clean the sentence \n",
        "data_file['clean_short_description'] = list(map(cleanSentence, data_file['short_description']))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RJm_iOdZLJBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus_text1 = '\\n'.join(data_file['clean_short_description'])\n",
        "sentences = corpus_text1.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8X1vP16sLDYD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = buildVocabulary(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FtVolj1mLOt0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QpcK3M_dLRmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a69ea46-fc44-4d90-c1af-4cf7eca0eed4"
      },
      "cell_type": "code",
      "source": [
        "print(vocab_size)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zSPwolPLLVQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "296bf422-8afd-40ec-a610-7dab64f69792"
      },
      "cell_type": "code",
      "source": [
        "data_file['word_count'] = data_file['clean_short_description'].apply(lambda x: len(str(x).split(\" \")))\n",
        "#incidents_data['word_count'] = incidents_data['short_description'].apply(lambda x: len(str(x).split(\" \")))\n",
        "data_file[['clean_short_description','word_count']].head(11)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_short_description</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>outlook crash</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>csrc pd98a</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>irn wont recieve</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>csrc svsbpl02</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>csrc saqcll51</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>irn recieve</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>lou t0317483 error</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>csrc job sub01702</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>triggered pod oracle printed yet orders needin...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>user unable connect vpn</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ap4 l2 sriram dammalapati 502340469 needed acc...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              clean_short_description  word_count\n",
              "0                                       outlook crash           2\n",
              "1                                          csrc pd98a           2\n",
              "2                                    irn wont recieve           3\n",
              "3                                       csrc svsbpl02           2\n",
              "4                                       csrc saqcll51           2\n",
              "5                                         irn recieve           2\n",
              "6                                  lou t0317483 error           3\n",
              "7                                   csrc job sub01702           3\n",
              "8   triggered pod oracle printed yet orders needin...          12\n",
              "9                             user unable connect vpn           4\n",
              "10  ap4 l2 sriram dammalapati 502340469 needed acc...           8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "9Zu80ee3LbUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2abde300-a9e5-4393-ac3f-d817c09b07b4"
      },
      "cell_type": "code",
      "source": [
        "d=data_file[\"word_count\"]\n",
        "d.value_counts()[:50].index"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([ 2,  3,  4,  5,  6,  7,  8,  9, 11, 10, 12, 13, 14,  1, 15, 16, 17,\n",
              "            18, 19, 20, 21, 24, 22, 23, 30, 28, 26, 27, 25, 32, 33, 38, 29, 34,\n",
              "            37, 31, 35, 36, 46, 40, 44, 42, 43, 50, 47, 45, 56, 54, 39, 80],\n",
              "           dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "ezpK7UcNLdMV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getTrainSequences(sentence, tokenizer,seq_maxlen):\n",
        "    sent1 = tokenizer.texts_to_sequences(sentence)\n",
        "    #sent_maxlen = max([len(s) for s in sent1])\n",
        "    #seq_maxlen = max([sent_maxlen])\n",
        "    return np.array(pad_sequences(sent1, maxlen=seq_maxlen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "auygo4KsLg9u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get sequences for each sentence pair tuple\n",
        "train_data_need = getTrainSequences(sentences, tokenizer,seq_maxlen=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FID5nmoNLjkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a37bd850-6b1d-4b7e-a5f4-be41f8ba6973"
      },
      "cell_type": "code",
      "source": [
        "train_data_need.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20227, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "hErbWoAZLnNT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences_w2c = [line.split(' ') for line in sentences]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMloEhRPLo7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model_w2v = Word2Vec(sentences_w2c, size=100, window=5, min_count=0, workers=4)\n",
        "vectors = model_w2v.wv\n",
        "#vectors.save(\"custom_w2v_vec.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s29G5BoxL02t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "461496ad-942c-45a3-9d67-f4d26b785fde"
      },
      "cell_type": "code",
      "source": [
        "print(len(list(vectors.vocab)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "miKMu_wKL5O2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_embed_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AI0J4im-L7Ul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getEmbeddingWeightMatrix_w2vec(w2vec_vectors,word2idx):    \n",
        "    embedding_matrix = np.zeros((len(word2idx)+1, word_embed_size))\n",
        "    for word, i in word2idx.items():\n",
        "        embedding_vector = w2vec_vectors[word]\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7BfWRLTXL-Hl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#get embedding layer weight matrix\n",
        "embedding_weight_matrix = getEmbeddingWeightMatrix_w2vec(vectors, tokenizer.word_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLLLP2WfMAnU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7afab34-a079-4934-bde6-569f97368615"
      },
      "cell_type": "code",
      "source": [
        "embedding_weight_matrix.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12483, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "vVHPjn4uMF8z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "3d1e121c-b383-47e6-e2c3-5b962a5a0861"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lb_make = LabelEncoder()\n",
        "data_file[\"cmdb_ci_code\"] = lb_make.fit_transform(data_file.cmdb_ci.astype(str))\n",
        "data_file[[\"cmdb_ci\", \"cmdb_ci_code\"]].head(11)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cmdb_ci</th>\n",
              "      <th>cmdb_ci_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Software - Microsoft Outlook</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CSRC ABEND</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Oracle EBS R12 Core - Inventory</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CSRC ABEND</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CSRC ABEND</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Oracle EBS R12 Core - Inventory</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Oracle EBS R12 Core - WSH-Shipping</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CSRC ABEND</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Oracle EBS R12 Core - WSH-Shipping</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>vpn service</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>AP4 P&amp;A List</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               cmdb_ci  cmdb_ci_code\n",
              "0         Software - Microsoft Outlook            32\n",
              "1                           CSRC ABEND             7\n",
              "2      Oracle EBS R12 Core - Inventory            24\n",
              "3                           CSRC ABEND             7\n",
              "4                           CSRC ABEND             7\n",
              "5      Oracle EBS R12 Core - Inventory            24\n",
              "6   Oracle EBS R12 Core - WSH-Shipping            27\n",
              "7                           CSRC ABEND             7\n",
              "8   Oracle EBS R12 Core - WSH-Shipping            27\n",
              "9                          vpn service            38\n",
              "10                        AP4 P&A List             4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "ddDMI18tMJaj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "1d165736-f378-4201-ba7c-7411c0546311"
      },
      "cell_type": "code",
      "source": [
        "tmp=data_file[[\"cmdb_ci\", \"cmdb_ci_code\"]]\n",
        "tmp = tmp.drop_duplicates('cmdb_ci')\n",
        "tmp.info()\n",
        "tmp['cmdb_ci_code']=tmp['cmdb_ci_code'].astype(str)\n",
        "from collections import defaultdict\n",
        "d = defaultdict(list)\n",
        "for i, j in zip(tmp.cmdb_ci_code,tmp.cmdb_ci):\n",
        "    d[i].append(j)\n",
        "d=dict(d)\n",
        "print(d)\n",
        "d['32'][0]\n",
        "x_train,x_test,y1_train,y1_test=train_test_split(train_data_need,data_file['cmdb_ci_code'], test_size=0.20, random_state=42, stratify=data_file['cmdb_ci_code'])\n",
        "x_train1,x_val,y1_train1,y1_val=train_test_split(x_train,y1_train, test_size=0.20, random_state=42, stratify=y1_train)\n",
        "#x_train1,x_test,y1_train1,y1_test=train_test_split(train_data_need,data_file['cmdb_ci_code'], test_size=0.20, random_state=42, stratify=data_file['cmdb_ci_code'])\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 40 entries, 0 to 2963\n",
            "Data columns (total 2 columns):\n",
            "cmdb_ci         40 non-null object\n",
            "cmdb_ci_code    40 non-null int64\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 960.0+ bytes\n",
            "{'32': ['Software - Microsoft Outlook'], '7': ['CSRC ABEND'], '24': ['Oracle EBS R12 Core - Inventory'], '27': ['Oracle EBS R12 Core - WSH-Shipping'], '38': ['vpn service'], '4': ['AP4 P&A List'], '25': ['Oracle EBS R12 Core - OM'], '10': ['Duo Security'], '17': ['General Question'], '31': ['Software'], '22': ['Office 365'], '37': ['password management'], '13': ['FS – TPTP Laptop Software'], '36': ['hardware-other'], '14': ['FS –TPTP Hardware Depot'], '35': ['hardware'], '5': ['AP5 P&A List'], '3': ['AP3 P&A List'], '16': ['GEA ServiceDesk – Hyderabad'], '15': ['GEA ServiceDesk – Bangalore'], '26': ['Oracle EBS R12 Core - PO Direct'], '8': ['Connectivity'], '6': ['BitLocker'], '39': ['windows 10'], '2': ['AP1 P&A List'], '23': ['Oracle EBS R12 Core'], '33': ['UltiPro'], '1': ['ACTIVE DIRECTORY'], '34': ['active directory - geindsys - amer'], '19': ['IDS - INTEGRATED DISTRIBUTION SYSTEM'], '12': ['Exchange'], '0': ['ACCOUNTS RECEIVABLE-APPL'], '21': ['OTD:SOASUITE-DOMAIN'], '18': ['IDENTITY MANAGER (IDM)'], '20': ['ORACLE TRANSPORTATION MANAGEMENT (OTM)'], '28': ['PD - WAREHOUSING'], '29': ['SC-MFG:SOASUITE-DOMAIN'], '30': ['SC-MFG:SVCBUS-DOMAIN'], '11': ['EBS OBIEE'], '9': ['DPO - DECATUR MANUFACTURING SITE, AL, UNITED STATES - GE APPLIANCES']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KpBheDZxMqB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d18dbd72-941b-48a2-bef3-d0de0039b4f5"
      },
      "cell_type": "code",
      "source": [
        "x_train1.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12944, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "ZkllFqY_Ms2c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "y1_train1 = np_utils.to_categorical(y1_train1)\n",
        "y1_test = np_utils.to_categorical(y1_test)\n",
        "y1_val=np_utils.to_categorical(y1_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQAIGt9KMv5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y1_train = np_utils.to_categorical(y1_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P6kLFFS_Zz5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target = np_utils.to_categorical(data_file['cmdb_ci_code'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tzPMM6L4Mzw8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers as initializers, regularizers, constraints\n",
        "from keras.callbacks import Callback\n",
        "from keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "class AttentionWithContext(Layer):    \n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        \n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JiEZ25r0M4S3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq_maxlen=50\n",
        "word_embed_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wOl2rt8bNBec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##Model Building on LSTM and  Attention layer\n",
        "input = Input(shape=(x_train1.shape[1],))\n",
        "\n",
        "inner = Embedding(input_dim=vocab_size, output_dim=word_embed_size, \n",
        "                   input_length=seq_maxlen, weights=[embedding_weight_matrix], \n",
        "                   trainable = True) (input)\n",
        "\n",
        "inner = LSTM(100, return_sequences=True)(inner)\n",
        "inner = Dropout(0.3)(inner)\n",
        "# compute importance for each step\n",
        "#inner = TimeDistributed(Dense(100))(inner) \n",
        "words_att = AttentionWithContext()(inner)\n",
        "\n",
        "inner = Dense(100, activation='relu')(words_att)\n",
        "#inner = Dense(40, activation='relu')(inner)\n",
        "output = Dense(y1_train1.shape[1], activation='softmax')(inner)\n",
        "\n",
        "model_a = Model(inputs = input, outputs = output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6dM2_Ro8NGMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_a.save('my_lstm_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tbGYD9SyNI_b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f034cf3f-7ced-4b12-8fae-7160b4236824"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "model_a1 = keras.models.load_model('my_lstm_model.h5', custom_objects={'AttentionWithContext':AttentionWithContext()})"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gKmnzm4gNN2m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "9cc2b7f7-c231-4481-8185-59d27f20569e"
      },
      "cell_type": "code",
      "source": [
        "print(model_a1.summary())\n",
        "model_a1.compile(Adam(lr=0.01), 'categorical_crossentropy', metrics=['accuracy'])\n",
        "#model_a.load_weights('/var/www/projects/nehru/text_classification/code/model_incidents_attention_lstm_word_vec_100d_n1.h5')\n",
        "\n",
        "save_weights = ModelCheckpoint('model_incidents_attention_lstm_word_vec_100d_new.h5', monitor='val_loss', save_best_only=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 50, 100)           1248300   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 50, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "attention_with_context_1 (At (None, 100)               10200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 40)                4040      \n",
            "=================================================================\n",
            "Total params: 1,353,040\n",
            "Trainable params: 1,353,040\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V6uidbaTNUHM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "model_json = model_a1.to_json()\n",
        "with open(\"model_incident_classification_lstm_attention.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fVoFFG4bNv7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1042
        },
        "outputId": "9df1e1e7-7ef8-432f-b162-e180f16f907b"
      },
      "cell_type": "code",
      "source": [
        "history = model_a1.fit(x=x_train1, y=y1_train1, batch_size=32,\n",
        "          epochs=30, validation_data=(x_val, y1_val), callbacks=[save_weights])\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 12944 samples, validate on 3237 samples\n",
            "Epoch 1/30\n",
            "12944/12944 [==============================] - 45s 3ms/step - loss: 1.5656 - acc: 0.5745 - val_loss: 1.1616 - val_acc: 0.6691\n",
            "Epoch 2/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.9809 - acc: 0.7073 - val_loss: 1.0604 - val_acc: 0.7028\n",
            "Epoch 3/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.7407 - acc: 0.7751 - val_loss: 1.0902 - val_acc: 0.7105\n",
            "Epoch 4/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.6137 - acc: 0.8123 - val_loss: 1.2120 - val_acc: 0.7000\n",
            "Epoch 5/30\n",
            "12944/12944 [==============================] - 45s 3ms/step - loss: 0.5248 - acc: 0.8425 - val_loss: 1.2554 - val_acc: 0.7152\n",
            "Epoch 6/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.4756 - acc: 0.8535 - val_loss: 1.3165 - val_acc: 0.7068\n",
            "Epoch 7/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.4361 - acc: 0.8644 - val_loss: 1.4475 - val_acc: 0.7139\n",
            "Epoch 8/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.4093 - acc: 0.8728 - val_loss: 1.5967 - val_acc: 0.6898\n",
            "Epoch 9/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3992 - acc: 0.8745 - val_loss: 1.6004 - val_acc: 0.7056\n",
            "Epoch 10/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3784 - acc: 0.8792 - val_loss: 1.7697 - val_acc: 0.7037\n",
            "Epoch 11/30\n",
            "12944/12944 [==============================] - 43s 3ms/step - loss: 0.3606 - acc: 0.8861 - val_loss: 1.7407 - val_acc: 0.6954\n",
            "Epoch 12/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3539 - acc: 0.8885 - val_loss: 1.8260 - val_acc: 0.6960\n",
            "Epoch 13/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3449 - acc: 0.8889 - val_loss: 1.8834 - val_acc: 0.7003\n",
            "Epoch 14/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3345 - acc: 0.8901 - val_loss: 1.8367 - val_acc: 0.6973\n",
            "Epoch 15/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3405 - acc: 0.8911 - val_loss: 1.8495 - val_acc: 0.6957\n",
            "Epoch 16/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3332 - acc: 0.8930 - val_loss: 1.8969 - val_acc: 0.6954\n",
            "Epoch 17/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3501 - acc: 0.8864 - val_loss: 1.8515 - val_acc: 0.6997\n",
            "Epoch 18/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3382 - acc: 0.8959 - val_loss: 1.9387 - val_acc: 0.6960\n",
            "Epoch 19/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3272 - acc: 0.8964 - val_loss: 2.0127 - val_acc: 0.6973\n",
            "Epoch 20/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3429 - acc: 0.8901 - val_loss: 2.1056 - val_acc: 0.6954\n",
            "Epoch 21/30\n",
            "12944/12944 [==============================] - 43s 3ms/step - loss: 0.3311 - acc: 0.8935 - val_loss: 1.9107 - val_acc: 0.7006\n",
            "Epoch 22/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3183 - acc: 0.8957 - val_loss: 2.2999 - val_acc: 0.6895\n",
            "Epoch 23/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3345 - acc: 0.8895 - val_loss: 2.0280 - val_acc: 0.6877\n",
            "Epoch 24/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3220 - acc: 0.8982 - val_loss: 2.0515 - val_acc: 0.6855\n",
            "Epoch 25/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3063 - acc: 0.9030 - val_loss: 2.3248 - val_acc: 0.6852\n",
            "Epoch 26/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3033 - acc: 0.9027 - val_loss: 2.4218 - val_acc: 0.6942\n",
            "Epoch 27/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3130 - acc: 0.8978 - val_loss: 2.3951 - val_acc: 0.6898\n",
            "Epoch 28/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3082 - acc: 0.9023 - val_loss: 2.0388 - val_acc: 0.6855\n",
            "Epoch 29/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3037 - acc: 0.9019 - val_loss: 2.2236 - val_acc: 0.6948\n",
            "Epoch 30/30\n",
            "12944/12944 [==============================] - 44s 3ms/step - loss: 0.3024 - acc: 0.9017 - val_loss: 2.0102 - val_acc: 0.6911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1SlHbBQaVvtz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted_lstm=model_a1.predict(x_test)\n",
        "predicted_lstm=predicted_lstm.argmax(axis=-1)\n",
        "y1_test=y1_test.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1MYQ4V7V5bc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accuracy1=np.mean(predicted_lstm==y1_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QR4TDxwbV7WF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2483e750-05c4-4b22-ec2b-1c85d9268e4f"
      },
      "cell_type": "code",
      "source": [
        "print(accuracy1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6811665842807711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H_Gui-UDWC2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "1f7229c1-f521-45b1-b2ac-31587a8dde9b"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "\n",
        "# Model reconstruction from JSON file\n",
        "with open('model_incident_classification_lstm_attention.json', 'r') as f:\n",
        "    model1 = model_from_json(f.read())\n",
        "\n",
        "# Load weights into the Model\n",
        "model1.load_weights('model_incidents_attention_lstm_word_vec_100d_new.h5')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-cf732e6f4791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Model reconstruction from JSON file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_incident_classification_lstm_attention.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Load weights into the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \"\"\"\n\u001b[1;32m    378\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 return cls.from_config(config['config'],\n\u001b[1;32m    143\u001b[0m                                        custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 144\u001b[0;31m                                                            list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   2523\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2524\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m         \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2510\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 2511\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   2512\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/__init__.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 138\u001b[0;31m                                  ': ' + class_name)\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'from_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mcustom_objects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_objects\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown layer: AttentionWithContext"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "z1Ud7zCRXXO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f07991ba-44c2-43ac-c9ea-4589735ff9a9"
      },
      "cell_type": "code",
      "source": [
        "model_1 = keras.models.load_model('my_lstm_model.h5', custom_objects={'AttentionWithContext':AttentionWithContext()})"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jyi0ZWpDXdKU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_1.load_weights('model_incidents_attention_lstm_word_vec_100d_new.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SMqJZ1QaXnUu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted_lstm1=model_1.predict(x_val)\n",
        "predicted_lstm1=predicted_lstm1.argmax(axis=-1)\n",
        "y1_val1=y1_val.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KvPB_eJ3Xu2F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accuracy1=np.mean(predicted_lstm1==y1_val1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pwqt3xSLXwvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63a3de54-f387-43b4-b1a3-c063d4a3bb16"
      },
      "cell_type": "code",
      "source": [
        "print(accuracy1)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7028112449799196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YcWQF20HYcit",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted_lstm2=model_1.predict(train_data_need)\n",
        "predicted_lstm2=predicted_lstm2.argmax(axis=-1)\n",
        "target1=target.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B4AXd9XzZZxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bda35d8-3f56-4ff5-ead7-b781ccfc0980"
      },
      "cell_type": "code",
      "source": [
        "accuracy1=np.mean(predicted_lstm2==target1)\n",
        "print(accuracy1)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7513224897414347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TqQmq1IVaWyW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted_lstm4=model_1.predict(x_train1)\n",
        "predicted_lstm4=predicted_lstm4.argmax(axis=-1)\n",
        "y1_trainn=y1_train1.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fr3VIsfMaYaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65a91037-1985-419a-b884-82d1b4803c07"
      },
      "cell_type": "code",
      "source": [
        "accuracy1=np.mean(predicted_lstm4==y1_trainn)\n",
        "print(accuracy1)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.784610630407911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u-z5R8AacXGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.savetxt('embedding_weight_matrix_custom_neh.txt', embedding_weight_matrix, fmt='%d')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}